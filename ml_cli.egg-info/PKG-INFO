Metadata-Version: 2.4
Name: ml_cli
Version: 0.1.0
Summary: A CLI tool for machine learning workflows
Home-page: https://github.com/yourusername/ml_cli
Author: Atunrase Ayomide
Author-email: atunraseayomide@gmail.com
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: setuptools>=65.0.0
Requires-Dist: pandas<2.3.0,>=2.0.0
Requires-Dist: click<9.0.0,>=8.0.0
Requires-Dist: rich-click<2.0.0,>=1.6.0
Requires-Dist: pyyaml<7.0.0,>=6.0.0
Requires-Dist: questionary<3.0.0,>=1.10.0
Requires-Dist: tqdm<5.0.0,>=4.60.0
Requires-Dist: rich<14.0.0,>=12.0.0
Requires-Dist: numpy<2.0.0,>=1.21.0
Requires-Dist: configparser<8.0.0,>=5.0.0
Requires-Dist: python-dotenv<2.0.0,>=0.19.0
Requires-Dist: requests<3.0.0,>=2.25.0
Requires-Dist: pytest<9.0.0,>=7.0.0
Requires-Dist: psutil>=5.8.0
Requires-Dist: fastapi<1.0.0,>=0.100.0
Requires-Dist: uvicorn<1.0.0,>=0.20.0
Requires-Dist: scikit-learn<2.0.0,>=1.1.0
Requires-Dist: joblib<2.0.0,>=1.1.0
Requires-Dist: tpot<2.0.0,>=0.12.0
Requires-Dist: matplotlib<4.0.0,>=3.5.0
Requires-Dist: seaborn<1.0.0,>=0.11.0
Requires-Dist: python-multipart>=0.0.5
Requires-Dist: gunicorn>=20.1.0
Requires-Dist: Jinja2<4.0.0,>=3.0.0
Requires-Dist: itsdangerous<3.0.0,>=2.0.0
Requires-Dist: python-jose<4.0.0,>=3.3.0
Requires-Dist: passlib<2.0.0,>=1.7.0
Requires-Dist: bcrypt<5.0.0,>=3.2.0
Requires-Dist: SQLAlchemy<3.0.0,>=1.4.0
Requires-Dist: psycopg2-binary<3.0.0,>=2.9.0
Requires-Dist: alembic<2.0.0,>=1.7.0
Requires-Dist: greenlet<4.0.0,>=1.1.0
Requires-Dist: pydantic-settings<3.0.0,>=2.0.0
Requires-Dist: certifi>=2021.0.0
Requires-Dist: pyarrow<16.0.0,>=10.0.0
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# ğŸ¤– ML CLI Pipeline

<div align="center">

[![Python Version](https://img.shields.io/badge/python-3.9%2B-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![PyPI Version](https://img.shields.io/badge/pypi-v0.1.0-orange.svg)](https://pypi.org/project/ml-cli/)
[![Tests](https://img.shields.io/badge/tests-passing-brightgreen.svg)](tests/)
[![Code Style](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

**A comprehensive command-line interface for end-to-end machine learning workflows**

[Quick Start](#-quick-start) â€¢ [Documentation](#-documentation) â€¢ [Examples](#-examples) â€¢ [Contributing](#-contributing)

</div>

## ğŸš€ Overview

ML CLI Pipeline is a powerful, user-friendly command-line tool that streamlines the entire machine learning workflow. From data exploration to model deployment, it provides a unified interface for data scientists and ML engineers to build, train, and serve machine learning models with minimal setup.

Built with modern Python technologies including **FastAPI**, **TPOT AutoML**, and **Click**, this tool eliminates the repetitive scripting often required in ML projects and provides production-ready model serving capabilities.

### âœ¨ Why ML CLI Pipeline?

- **ğŸ¯ Zero Configuration**: Get started with a single command - no complex setup files
- **ğŸ”„ End-to-End Workflow**: Complete ML pipeline from EDA to production deployment
- **ğŸ¤– AutoML Integration**: Leverage TPOT for automated model selection and hyperparameter tuning
- **ğŸš€ Production Ready**: Built-in FastAPI server for immediate model deployment
- **ğŸ“Š Rich Visualizations**: Automated EDA reports with beautiful plots and statistics
- **ğŸ”§ Flexible Configuration**: Support for both YAML and JSON configuration formats
- **ğŸ§ª Thoroughly Tested**: Comprehensive test suite ensuring reliability

## âœ¨ Features

<table>
<tr>
<td width="50%">

### ğŸ› ï¸ **Core Capabilities**
- **Interactive Project Setup** - Guided initialization with intelligent defaults
- **Automated EDA** - Comprehensive data analysis with visualizations
- **Smart Preprocessing** - Automatic categorical encoding and data cleaning
- **AutoML Training** - TPOT-powered model optimization
- **Flexible Prediction** - Easy inference on new data
- **Production Serving** - FastAPI-based REST API deployment

</td>
<td width="50%">

### ğŸ¯ **Advanced Features**
- **Dynamic API Documentation** - Auto-generated examples from your data
- **Model Reloading** - Hot-reload models without server restart
- **Artifact Tracking** - Automatic cleanup of generated files
- **Multi-format Support** - CSV, JSON, and remote URL data sources
- **SSL Support** - Secure data fetching from HTTPS sources
- **Rich CLI Interface** - Beautiful terminal output with progress bars

</td>
</tr>
</table>

## ğŸ› ï¸ Installation

### Prerequisites
- Python 3.9 or higher
- pip (Python package installer)

### Quick Install

```bash
# Clone the repository
git clone https://github.com/Ayo-Cyber/ml_cli.git
cd ml_cli

# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install in development mode
pip install -e .
```

### Verify Installation

```bash
ml --help
```

You should see the ML CLI help menu with all available commands.

## ğŸš€ Quick Start

Get up and running in under 5 minutes:

### 1. Initialize Your Project

```bash
ml init
```

This interactive command will:
- Guide you through project setup
- Validate your data file
- Create optimized configuration
- Set up your workspace

### 2. Explore Your Data

```bash
ml eda
```

Generates comprehensive analysis including:
- ğŸ“Š Summary statistics (`summary_statistics.csv`)
- ğŸ“ˆ Missing value reports (`eda_report.csv`)
- ğŸ”¥ Correlation heatmaps (`correlation_matrix.png`)

### 3. Preprocess Your Data

```bash
ml preprocess
```

Automatically handles:
- One-hot encoding for categorical variables
- Data validation and cleaning
- Feature preparation for training

### 4. Train Your Model

```bash
ml train
```

Leverages TPOT AutoML to:
- Find optimal algorithms
- Tune hyperparameters
- Export production-ready models
- Generate performance metrics

### 5. Serve Your Model

```bash
ml serve
```

Instantly deploy your model with:
- ğŸŒ RESTful API endpoints
- ğŸ“š Interactive documentation at `/docs`
- ğŸ”„ Hot-reload capabilities
- ğŸ“ Auto-generated examples

## ğŸ“– Documentation

### Command Reference

<details>
<summary><b>ğŸ”§ ml init</b> - Initialize new ML project</summary>

```bash
ml init [OPTIONS]
```

**Options:**
- `--format [yaml|json]` - Configuration format (default: yaml)
- `--ssl-verify/--no-ssl-verify` - SSL verification for URLs (default: enabled)

**Features:**
- Interactive project setup wizard
- Data validation and target column detection
- Intelligent default suggestions
- Support for local files and URLs

</details>

<details>
<summary><b>ğŸ“Š ml eda</b> - Exploratory Data Analysis</summary>

```bash
ml eda
```

**Generates:**
- Summary statistics for all features
- Missing value analysis
- Data type information
- Correlation matrix visualization

**Output Files:**
- `summary_statistics.csv`
- `eda_report.csv` 
- `correlation_matrix.png`

</details>

<details>
<summary><b>ğŸ§¹ ml preprocess</b> - Data Preprocessing</summary>

```bash
ml preprocess [OPTIONS]
```

**Options:**
- `--config, -c PATH` - Configuration file path (default: config.yaml)

**Features:**
- Automatic categorical variable encoding
- Data validation and cleaning
- Preprocessed data export

</details>

<details>
<summary><b>ğŸ¤– ml train</b> - Model Training</summary>

```bash
ml train [OPTIONS]
```

**Options:**
- `--config, -c PATH` - Configuration file path (default: config.yaml)

**Outputs:**
- `fitted_pipeline.pkl` - Serialized model
- `best_model_pipeline.py` - Exportable Python script
- `feature_info.json` - Model metadata and statistics

</details>

<details>
<summary><b>ğŸ”® ml predict</b> - Make Predictions</summary>

```bash
ml predict -i INPUT_FILE -o OUTPUT_FILE -m MODEL_DIR
```

**Required Options:**
- `-i, --input-path PATH` - Input CSV file
- `-o, --output-path PATH` - Output predictions file
- `-m, --model-path PATH` - Model directory

</details>

<details>
<summary><b>ğŸš€ ml serve</b> - Model Serving</summary>

```bash
ml serve [OPTIONS]
```

**Options:**
- `--host TEXT` - Host address (default: 127.0.0.1)
- `--port INTEGER` - Port number (default: 8000)
- `--reload/--no-reload` - Auto-reload on changes (default: True)
- `--config, -c PATH` - Configuration file (default: config.yaml)

**API Endpoints:**
- `GET /` - API information
- `GET /health` - Health check
- `GET /model-info` - Model metadata
- `POST /predict` - Make predictions
- `GET /docs` - Interactive documentation

</details>

<details>
<summary><b>ğŸ§¹ ml clean</b> - Cleanup Artifacts</summary>

```bash
ml clean
```

Removes all generated files tracked in `.artifacts.log`

</details>

### Configuration Format

The [`ml init`](ml_cli/commands/init.py) command creates a configuration file with the following structure:

```yaml
# config.yaml
data:
  data_path: 'data/your_dataset.csv'
  target_column: 'target'

task:
  type: 'classification'  # or 'regression', 'clustering'

output_dir: 'output'

tpot:
  generations: 4
  population_size: 20
  verbosity: 2

training:
  test_size: 0.2
  random_state: 42
```

## ğŸ’¡ Examples

### Complete Workflow Example

```bash
# 1. Set up project
ml init
# Follow prompts to configure your project

# 2. Analyze your data
ml eda

# 3. Prepare data for training
ml preprocess

# 4. Train your model
ml train

# 5. Start API server
ml serve --port 8080

# 6. Test your API
curl -X POST "http://localhost:8080/predict" \
     -H "Content-Type: application/json" \
     -d '{"feature1": 1.0, "feature2": 2.0}'
```

### Working with Remote Data

```bash
# Initialize with remote dataset
ml init
# Enter URL: https://example.com/dataset.csv

# The tool automatically downloads and validates the data
```

### Custom Configuration

```bash
# Use JSON configuration
ml init --format json

# Train with custom config
ml train --config my_config.yaml

# Serve with custom host/port
ml serve --host 0.0.0.0 --port 9000
```

## ğŸ—ï¸ Architecture

<div align="center">

```mermaid
graph TB
    A[ml init] --> B[Configuration Setup]
    B --> C[ml eda]
    C --> D[Data Analysis]
    D --> E[ml preprocess]
    E --> F[Data Cleaning]
    F --> G[ml train]
    G --> H[TPOT AutoML]
    H --> I[Model Export]
    I --> J[ml serve]
    J --> K[FastAPI Server]
    
    style A fill:#e1f5fe
    style G fill:#f3e5f5
    style J fill:#e8f5e8
```

</div>

### Project Structure

```
ml_cli/
â”œâ”€â”€ ğŸ“ ml_cli/
â”‚   â”œâ”€â”€ ğŸŒ api/              # FastAPI application
â”‚   â”‚   â””â”€â”€ main.py          # API endpoints and model serving
â”‚   â”œâ”€â”€ âš¡ commands/         # CLI command implementations
â”‚   â”‚   â”œâ”€â”€ init.py          # Project initialization
â”‚   â”‚   â”œâ”€â”€ eda.py           # Exploratory data analysis
â”‚   â”‚   â”œâ”€â”€ train.py         # Model training
â”‚   â”‚   â”œâ”€â”€ serve.py         # Model serving
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ ğŸ§  core/            # Core ML logic
â”‚   â”‚   â”œâ”€â”€ data.py          # Data loading and validation
â”‚   â”‚   â””â”€â”€ train.py         # Training algorithms
â”‚   â”œâ”€â”€ ğŸ› ï¸ utils/           # Utility functions
â”‚   â”‚   â””â”€â”€ utils.py         # Helper functions
â”‚   â””â”€â”€ ğŸš€ cli.py           # Main CLI entry point
â”œâ”€â”€ ğŸ§ª tests/               # Comprehensive test suite
â”œâ”€â”€ ğŸ“Š examples/            # Example datasets
â”œâ”€â”€ ğŸ“‹ requirements.txt     # Dependencies
â””â”€â”€ âš™ï¸ setup.py            # Package configuration
```

## ğŸ§ª Testing

Run the comprehensive test suite:

```bash
# Run all tests
python -m pytest

# Run with coverage
python -m pytest --cov=ml_cli

# Run specific test file
python -m pytest tests/test_cli.py -v
```

### Test the API

Use the included [test script](test_api.py):

```bash
# Start the server
ml serve

# Run API tests (in another terminal)
python test_api.py
```

## ğŸ¤ Contributing

We welcome contributions! Here's how to get started:

### Development Setup

```bash
# Fork and clone the repository
git clone https://github.com/YOUR_USERNAME/ml_cli.git
cd ml_cli

# Create development environment
python -m venv venv
source venv/bin/activate

# Install in development mode with test dependencies
pip install -e .
pip install pytest pytest-cov black flake8

# Run tests to ensure everything works
pytest
```

### Contributing Guidelines

1. **ğŸ´ Fork** the repository
2. **ğŸŒ¿ Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **âœ… Test** your changes (`pytest`)
4. **ğŸ’« Format** your code (`black ml_cli/`)
5. **ğŸ“ Commit** your changes (`git commit -m 'feat: Add amazing feature'`)
6. **ğŸš€ Push** to the branch (`git push origin feature/amazing-feature`)
7. **ğŸ“¬ Open** a Pull Request

### Code Standards

- Follow [PEP 8](https://pep8.org/) style guidelines
- Use [Black](https://github.com/psf/black) for code formatting
- Write comprehensive tests for new features
- Update documentation for user-facing changes

## ğŸ“ˆ Roadmap

### Upcoming Features

- [ ] ğŸ³ **Docker Support** - Containerized deployment
- [ ] â˜ï¸ **Cloud Integration** - AWS/GCP/Azure deployment
- [ ] ğŸ“± **Web UI** - Browser-based interface
- [ ] ğŸ”„ **Model Versioning** - Track model iterations
- [ ] ğŸ“Š **Advanced Metrics** - Detailed performance analytics
- [ ] ğŸ›¡ï¸ **Model Monitoring** - Production model tracking
- [ ] ğŸ”Œ **Plugin System** - Custom algorithm integration

### Performance Improvements

- [ ] âš¡ **Parallel Processing** - Multi-core training
- [ ] ğŸ’¾ **Caching** - Intelligent result caching
- [ ] ğŸ“¦ **Model Compression** - Optimized model sizes

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

### Getting Help

- ğŸ“š **Documentation**: Check this README and inline help (`ml --help`)
- ğŸ› **Bug Reports**: [Open an issue](https://github.com/Ayo-Cyber/ml_cli/issues)
- ğŸ’¡ **Feature Requests**: [Start a discussion](https://github.com/Ayo-Cyber/ml_cli/discussions)
- ğŸ“§ **Direct Contact**: atunraseayomide@gmail.com

### FAQ

<details>
<summary><b>Q: What data formats are supported?</b></summary>

A: Currently supports CSV, TXT, and JSON files. Both local files and remote URLs (HTTP/HTTPS) are supported.
</details>

<details>
<summary><b>Q: Can I use custom machine learning algorithms?</b></summary>

A: Currently, the tool uses TPOT for AutoML. Custom algorithms will be supported in future versions through the plugin system.
</details>

<details>
<summary><b>Q: How do I deploy models to production?</b></summary>

A: Use `ml serve` to create a production-ready FastAPI server. For advanced deployment, consider using Docker or cloud platforms.
</details>

<details>
<summary><b>Q: Is GPU training supported?</b></summary>

A: GPU support depends on the underlying TPOT and scikit-learn implementations. Future versions will include explicit GPU acceleration.
</details>

---

<div align="center">

**â­ Star this repo if you find it helpful!**

Made with â¤ï¸ by [Atunrase Ayomide](https://github.com/Ayo-Cyber)

[ğŸ  Home](https://github.com/Ayo-Cyber/ml_cli) â€¢ [ğŸ“– Docs](#-documentation) â€¢ [ğŸ› Issues](https://github.com/Ayo-Cyber/ml_cli/issues) â€¢ [ğŸ’¬ Discussions](https://github.com/Ayo-Cyber/ml_cli/discussions)

</div>
